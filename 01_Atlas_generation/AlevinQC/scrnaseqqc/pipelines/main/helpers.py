import re
import os
from warnings import warn
from pathlib import Path
from typing import Optional, Union, List, Dict, Set
from collections import OrderedDict

def getpath(string):
    if string in ['', '.', './']:
        return ''
    if string.startswith('./'):
        regex = re.compile(r'^\./?')
        string = regex.sub('', string)
    if not string.endswith('/'):
        string += '/'
    return string


class Targets:
    
    # class
    def __init__(self, components: dict, targets: OrderedDict):
      """Determines the target (files) that have to be generated by rule `all` based on the
      user-defined components. components: components as keys and logical as value,
      targets: dictionary with rule output as values and the components as keys"""
	    
      self.components = components
      self.selected_components = self.components_to_select()
      self.target_by_component = targets
      self.selected_targets = self.targets_from_components()

    # some instance
    def __str__(self):
        return f"The following targets are included: {self.selected_targets}"
        
    def targets_from_components(self) -> List[str]:
        """Determines the target (files) that have to be generated by rule `all` based on the
        user-defined components."""
        selected_targets = [self.target_by_component[component]
                            for component in self.selected_components]
        return selected_targets        
        
    def flat(self) -> List[str]:
        """Flattens lists of lists (nested list)"""
        return [item for sublist in self.selected_targets for item in sublist]
        
    def components_to_select(self) -> List[str]:
        """Processes the components that should be included as defined in the config and returns
        the names for which the component was set to True"""
        selected_components = [component for component, include in self.components.items()
                               if include]
        return selected_components


class FastqFileNames:
    # https://support.illumina.com/help/BaseSpace_OLH_009008/Content/Source/Informatics/BS/
    # NamingConvention_FASTQ-files-swBS.htm

    ### Examples
    # Tested and working with:
    # 50_3_L1_R1_001.fastq.gz
    # M_1_S1_L001_R2_001.fastq.gz
    # 32_GEX_3_L1_R2_001.fastq.gz
    # 42_2_L1_R2_001.fastq.gz
    # ID2066_G_4_L2_R1_001.fastq.gz
    #
    # Filenames from:
    # /home/common/data/projects/ScaiBmd/hnscc_old/fastq/
    # /home/common/data/customerdata/insel-frauenklinik/7edb15d0-439e-4eb4-ba50-900cc4f0e7d9
    # /home/common/data/projects/ScaiBmd/endometriosis/scrnaseq/Experiment6/data/fastqs/

    ###### Initialise class ######

    def __init__(self, dir_in: Path, assumptions: Dict[str, str] = None,
                 excludes: List[str] = None):
        """detects the filename format based on dir_in and saves this information to member
        variables. Calls the private methods _verify_filenames and _verify_counts to ensure all
        file follow the same convention. Custom regex naming assumptions and known parts excluded
        using the optional options."""

        # use first fastq.gz file to derive information
        self.dir_in = Path(dir_in)
        self.all_fastq_files = sorted([str(file.name) for file in self.dir_in.glob("*fastq*")])

        if len(self.all_fastq_files) < 1:
            exit(f"No Fastq files found in '{dir_in}'.")

        self.assumptions = {"index": "_G", "lane": "_L", "read": "_R", "hash": "_"}

        if assumptions != "None" and assumptions != "" and assumptions is not None and \
                assumptions != "{}" and assumptions != {}:
            possible_keys = ["index", "lane", "read", "hash"]

            # confirm keys in provided assumptions dictionary are valid and update if true
            if all(key in possible_keys for key in assumptions):
                for key in assumptions:
                    self.assumptions[key] = assumptions[key]

            else:
                warn(f"Supplied assumptions dictionary: '{assumptions}' does not contain the "
                     f"correct key(s). The assumptions dictionary must contain only one or more of "
                     f"these four keys: `index`, `lane`, `read`, `hash`.")

        # extract extension and convert to regex-friendly format
        self.plain_extension = re.search(r"(\..+$)", self.all_fastq_files[0]).group(0)
        self.extension = self.plain_extension.replace(".", r"[.]")

        # construction of dictionary of re objects for parts of first file
        self.contains = self._contains(self.all_fastq_files[0])

        # if exclusions have been set, manually remove these from self.contains, even if matched
        if excludes is not None:
            possible_excludes = [part for part in self.contains]

            # confirm exclude is a valid part
            for exclude in excludes:
                if exclude in possible_excludes:
                    self.contains[exclude] = None

                else:
                    warn(f"Cannot exclude {exclude} as it is not a valid part. Please choose from "
                        f"one of {possible_excludes}.")

        # create dictionary of zfills to account for zeros in naming conventions
        self.zfills = self._get_zfills()

        # get convention regex for finding all matching files
        self.convention = self._get_regex()

        # verify all files follow the correct convention
        self._verify_filenames()

        # get all filenames matching convention
        self.filenames = self.get_filenames()

        # only continue verification if matching files are found to prevent error
        if self.filenames is None:
            warn("No fastq files found. Try adjusting assumptions and/or exclude.")

        else:
            # get filename wildcard convention
            self.filenames_as_wildcards = self.get_filenames_as_wildcards()

            # verify there are the same number of files for each sample
            self._verify_counts()

            # logging to user to ensure behaviour is expected.
            print(f"** Automatic detection of fastq file names and naming convention is complete.\n"
                  f"** It is advised to double check the parameters below and ensure they matches "
                  f"the expected outcome.\n"
                  f"** If there is undesired behaviour, use CTRL-c to kill the pipe and adjust the "
                  f"'assumptions' and 'exclusions' options in the configuration file to correct "
                  f"the behaviour. The following sample names have been detected:\n"
                  f"{self.get_sample_names()}\n"
                  f"from files with the following parts:"
                  f"{[part for part in self.contains if self.contains[part]]}")

    def __repr__(self) -> str:
        """represents object in human readable form when printed."""
        return f"Contains filenames, parts and naming convention of files in {self.dir_in}."

    ###### Detect and verify the file naming and structure
    def get_counts(self) -> Dict[str, int]:
        """returns a dictionary containing the count of files for each sample"""
        names = self.get_sample_names(return_only_unique=False)
        return dict((i, names.count(i)) for i in names)

    def _contains(self, filename) -> Dict[str, re.search]:
        """takes a filename and returns a dictionary of parts as re.search objects"""
        # convert filename to string in case supplied as a Path object
        filename = str(filename)

        # Note: Regex built using assumptions dictionary but further assumptions are made:
        # index is assumed to be the first digits after the initial letter, unless the
        # sample name is the format .*_.*_.* in which case the index is assumed to be after this
        # It is assumed there is always a sample name.
        parts = {"index": re.search(rf"^.*?_(?:[A-Za-z]*_(\d*)|(\d*)_[{self.assumptions['lane']}"
                                    rf"{self.assumptions['read']}0]).*$", filename),
                 "lane": re.search(rf"{self.assumptions['lane']}(\d+)[_{self.plain_extension}]",
                                   filename),
                 "read": re.search(rf".*{self.assumptions['read']}(\d)+[_{self.plain_extension}]",
                                   filename),
                 "hash": re.search(rf".*{self.assumptions['hash']}(.*){self.extension}$",
                                   filename)}

        # if function is run outside of __init__ add sample_name to the return dictionary
        if hasattr(self, 'convention'):
            parts["sample_name"] = re.search(self.convention, filename.split("/")[-1]).group(1),

        return parts

    def _get_zfills(self) -> Dict[str, int]:
        """creates a dictionary of zfill length for each part"""
        return {part: len(self.contains[part].group(1)) if self.contains[part] and self.contains[
            part].group(1) is not None else 0 for part in self.contains}

    def _get_regex(self, options: Dict[str, str] = None, exclude_read=False) -> str:
        """builds regex either for specific files based on parts in options dictionary,
        or a generic convention based on the file naming if no dictionary is supplied. If
        exclude_read is set to True (default: False) regex will be supplied with capture groups
        excluding the read."""
        # add defaults to find generic convention if no options dictionary supplied
        if options is None:
            options = {"sample_name": r".*", "read": r"[12]", "lane": r"\d+", "index": r"\d+",
                       "hash": ".*"}
        sample_name = options["sample_name"]

        # build regex based on information extracted in init
        index_str = "" if not self.contains["index"] else self.assumptions["index"] \
                    + str(options["index"]).zfill(self.zfills["index"])
        lane_str = "" if not self.contains["lane"] else self.assumptions["lane"] \
                   + str(options["lane"]).zfill(self.zfills["lane"])
        read_str = "" if not self.contains["read"] else self.assumptions["read"]\
                   + str(options["read"]).zfill(self.zfills["read"])
        hash_str = "" if not self.contains["hash"] else self.assumptions["hash"]\
                   + str(options["hash"])

        if exclude_read:
            regex = rf"^({sample_name}{index_str}{lane_str}){read_str}({hash_str}{self.extension})$"
        else:
            regex = rf"^({sample_name})({index_str})({lane_str})({read_str})({hash_str})" \
                    rf"{self.extension}$"

        return regex

    def _verify_counts(self):
        """checks whether there are an equal number of files for each sample"""
        counts = self.get_counts()
        if counts != {}:
            max_key = max(counts, key=counts.get)
        else:
            exit("NoSamplesFound: No samples matched the regex. Try adjusting the assumptions "
                 "dictionary and exclusion list.")

        samples_missing_files = [str(sample_count) for sample_count in counts if counts[
                                 sample_count] < int(counts[max_key])]
        if len(samples_missing_files) != 0:
            warn(f"There are too few matching input files for the following samples:\n"
                 f"{samples_missing_files}.\n"
                 f"Consider changing the names of these files if they are present in "
                 f"{self.dir_in}.")

    def _verify_filenames(self):
        """checks whether all imported files follow the naming convention"""
        excluded_files = [fastq_filename for fastq_filename in self.all_fastq_files if not
                          re.search(self.convention, str(fastq_filename))]

        # warn if not all files match the convention
        if len(excluded_files) != 0:
            warn(f"** The supplied input directory {self.dir_in} contains !{len(excluded_files)}! "
                 f"files that do not match the naming convention defined in this regex: "
                 f"\'{self.convention}\'.\nThe following files have been excluded from the pipe:\n"
                 f" {', '.join(excluded_files)}")

    ###### Get literal file names ######
    def get_filenames(self, sample_name: Optional[str] = None, index: Optional[str] = None,
                      lane: Optional[str] = None, read: Optional[str] = None,
                      file_hash: Optional[str] = None,
                      contains: Optional[Dict[str, re.search]] = None,
                      as_path=True, exclude_read=False) \
            -> List[Path] or List[str]:
        """finds all files in self.dir_in matching the specified parts or auto_detected naming
        convention if no parts are specified. Uses default "contains" dictionary unless another is
        supplied. If exclude_read is True (default: False) filenames will be returned excluding
        the read portion of the filename and will always be returned as strings (ignoring
        'as_path') because paths will not match input fastqs."""
        # create dictionary of options
        options = {"sample_name": sample_name, "index": index, "lane": lane, "read": read,
                   "hash": file_hash}

        # if no contains dictionary is supplied, use the automatically generated one
        contains = self.contains if contains is None else contains

        # warn user if a supplied part is not a part present in the original filename structure
        # (ignoring sample name which is always present).
        for part in contains:
            if not contains[part] and options[part] is not None and options[part] != "sample_name":
                warn(f"** The original file names do not contain a(n) {part}. Ignoring the "
                     f"provided {part}.")

        # add wildcards to any variable user has not specified - ignored in get_regex
        # function if not present in the original filenames.
        options = {option: r".*" if search is None else search for (option, search) in
                   options.items()}

        search_regex = self._get_regex(options, exclude_read=exclude_read)

        # if excluding reads format file names without reads, otherwise simply use search regex
        if exclude_read:
            # prevent incorrect paths being returned
            as_path = False

            matching_filenames = [re.match(search_regex, str(filename)).group(1) +
                                  re.match(search_regex, str(filename)).group(2)
                                  for filename in self.all_fastq_files if
                                  re.match(search_regex, str(filename))]
        else:
            matching_filenames = [Path(filename) for filename in self.all_fastq_files if
                                  re.match(search_regex, str(filename))]

        if len(matching_filenames) == 0:
            warn(f"** No files were found using the parts:\n"
                 f"sample_name: {sample_name}\n"
                 f"index: {index}\n"
                 f"lane: {lane}\n"
                 f"read: {read}")
        else:
            file_paths = [self.dir_in / filename if as_path else str(filename) for filename in
                          matching_filenames]
            return file_paths

    def get_sample_names(self, return_only_unique=True, return_clean=False,
                         filenames: List[str] = None) -> List[str]:
        """returns a sorted list with the unique sample names that are part of the filenames in the
        folder. If return_only_unique is False (default True) will return all sample names as
        many time as they are present in the directory. If return_clean is True (default: False)
        will return a clean list of sample names without sequencer-added characters. NOTE: this will
        not work for calling samples as will not match filenames. If a list of filenames is
        provided, retrieves only sample names from that list, otherwise returns sample names from
        all discovered files."""

        # if no list of filenames is provided use all discovered files to discover sample names
        if not filenames:
            filenames = self.filenames

        # get filename from path if convention matches that file
        names = [re.search(self.convention, str(filename).split("/")[-1]).group(1) for filename
                 in filenames if re.search(self.convention, str(filename).split("/")[-1]) is
                 not None]

        # remove false None values from names list
        names = list(filter(None, names))

        def clean(sample_name):
            """cleans trailing letters off of sample names unless the sample name has multiple
            parts"""
            search = re.search(r"^([^_]*?)_[^_]*$", sample_name)
            if search:
                return search.group(1)
            else:
                return sample_name

        # format list of names based on function options
        if return_clean:
            names = [clean(sample_name) for sample_name in names]

        if return_only_unique:
            names = [name for name in set(names)]
            names.sort()

        return names

    def get_parts_dictionary(self) -> Dict[str, List[str]]:
        """returns a dictionary containing as keys all of the parts present in the filenames, and
        as values a list of all possible variations for that part from the files in dir_in."""
        # detail which capture group relates to which part in self.convention regex
        regex_group_number = {"index": 2, "lane": 3, "read": 4, "hash": 5}

        def clean_literal_part_list(part: str) -> List[str]:
            """returns a unique list of strings matching the specified literal part"""
            # get parts
            literal_parts_list = [re.search(self.convention, str(filename).split("/")[-1])
                                          .group(regex_group_number[part])
                                  for filename in self.filenames]

            # remove duplicates and sort list
            literal_parts_list = [part for part in set(literal_parts_list)]
            literal_parts_list.sort()

            # remove prepending underscore if present
            literal_parts_list = [re.search(r"^_(.*)", part).group(1) if re.search(r"^_.*", part)
                                  else part for part in literal_parts_list]

            return literal_parts_list

        # create dictinary of literal parts
        literal_parts = {part: clean_literal_part_list(part) if part else None for part in
                         self.contains}

        # add sample names to dictionary
        literal_parts.update({"sample_name": self.get_sample_names()})

        return literal_parts

    def get_alternate_read(self, sample_filename: str, as_path=False) -> List[str] or None:
        """returns filename of the other read for that sample for a given filename, unless other
        file cannot be found when it returns None."""
        # remove path (in case filename is supplied as a path)
        sample_filename = str(sample_filename).split("/")[-1]

        # get dictionary of parts and convert from re.search objects to strings
        parts = self._contains(sample_filename)
        string_parts = {part: parts[part].group(1) for part in parts}

        # if no read found in filename warn user and return None
        if not parts["read"]:
            warn(f"{sample_filename} contains no read number so cannot return the other read."
                 f"Function will return None.")
            return None

        else:
            if string_parts["read"] == "1":
                return_read_num = "2"
            elif string_parts["read"] == "2":
                return_read_num = "1"
            # if read is not 1 or 2 warn user and return None
            else:
                warn(f"{sample_filename} appears to be neither Read 1 no Read 2. Ambiguous desired "
                     f"read so returning None.")
                return None

            return self.get_filenames(sample_name=string_parts["sample_name"],
                                      index=string_parts["index"],
                                      lane=string_parts["label"],
                                      read=return_read_num, as_path=as_path)

    def get_semi_literal_names(self, read: Optional[int] = None) -> List[str]:
        """returns a semi-literal list of filename paths in string format, containing only the
        'sample' wildcard. Returns only those files of a particular read if a read is specified,
        default None."""

        # get list of literal filenames from first file
        first_sample_name = self.get_sample_names()[0]
        literal_names_list = self.get_filenames(sample_name=first_sample_name, read=read)

        # replace sample name with "{sample}" in each literal filename to create semi-literal names
        return [str(name).replace(first_sample_name, "{sample}") for name in
                literal_names_list]

    @property
    def get_literal_names_by_lane(self) -> Optional[Dict[str, str]]:
        """returns a dictionary where:
        key = Lane Number as a string (usually between '001'->'004')
        value = Literal file names for each input file (read independant)"""

        if self.contains["lane"]:
            return {lane: self.get_filenames(lane=lane[1:], exclude_read=True, as_path=False)
                    for lane in self.get_parts_dictionary()["lane"]}

        else:
            warn("Filenames do not contain a 'Lane' part, therefore cannot create a lanes "
                 "dictionary")

    @property
    def get_sample_names_by_lane(self) -> Optional[Dict[str, str]]:
        """returns a dictionary where:
        key = Lane Number as a string (usually between '001'->'004')
        value = Sample names for each input file"""

        if self.contains["lane"]:
            return {lane: self.get_sample_names(filenames=self.get_filenames(lane=lane[1:],
                                                                             read="1"))
                for lane in self.get_parts_dictionary()["lane"]}

        else:
            warn("Filenames do not contain a 'Lane' part, therefore cannot create a lanes "
                 "dictionary")

    @property
    def read_independant_literal_filenames(self) -> List[str]:
        """returns a list of strings including the availiable parts of the filename but excluding
        the read portion."""
        return self.get_filenames(exclude_read=True, as_path=False)

    @property
    def literal_filenames_no_ext(self) -> List[str]:
        """returns a list of strings including the availiable parts of the filename in literal
        format but excluding the extension."""
        filenames = self.get_filenames(as_path=False)
        return [filename.split(self.plain_extension)[0] for filename in filenames]

    ###### Determine wildcard file names ######
    def get_filenames_as_wildcards(self, contains: Optional[Dict[str, re.search]] = None) -> str:
        """returns one string which includes all wildcards for the filenames. Uses a custom
        contains dictionary if supplied."""
        # if no contains dictionary is supplied, use the automatically generated one
        contains = self.contains if contains is None else contains

        wildcard_parts = {str(part): "_{%s}" % part if contains[part] else "" for part in
                          contains}
        wildcard_filename = "{sample}" + wildcard_parts["index"] + wildcard_parts["lane"] \
                            + wildcard_parts["read"] + wildcard_parts["hash"] + self.plain_extension
        return wildcard_filename

    def _wildcard_filenames_fix_part(self, wildcard_filenames: str, part: str, fix_to: str) -> str:
        """fixes the specified wildcard part to a specific value"""

        # warn if user is trying to change the index without a defined index identifier string
        if part == "index" and self.assumptions["index"] == "":
            warn("By default there is no index string set so wildcards relying on specific "
                 "indices are unlikely to work. Add an index string identifer to the assumptions "
                 "dictionary to hide this error. This can be done ")

        part_term = self.assumptions[part] + fix_to
        fixed_part = wildcard_filenames.replace("_{" + part + "}", part_term)

        return fixed_part

    @property
    def read_independant_wildcard_filenames(self) -> str:
        """returns a string with wildcards dynamically including the availiable parts of the
        filename but excluding the read wildcard."""
        # create custom contains dictionary to exclude read
        contains = {part: False if part == "read" else self.contains[part] for part in
                    self.contains}

        return self.get_filenames_as_wildcards(contains=contains)

    @property
    def r1_names(self) -> str:
        """returns string with wildcards, but with read fixed to 1"""
        return self._wildcard_filenames_fix_part(self.filenames_as_wildcards, "read", "1")

    @property
    def r2_names(self) -> str:
        """returns string with wildcards, but with read fixed to 2"""
        return self._wildcard_filenames_fix_part(self.filenames_as_wildcards, "read", "2")

    @property
    def wildcard_filenames_no_ext(self) -> str:
        """returns a string including the availiable parts of the filename in wildcard format but
        excluding the extension."""
        wildcard = self.get_filenames_as_wildcards()
        return wildcard.split(self.plain_extension)[0]

class CountFileNames:
    """retrieves count matrix files, automatically detecting the naming convention in the input
    directory"""

    def __init__(self, dir_in: Path):
        """like FastqFileNames but for counts. Detects the filename format based on dir_in and
        saves this information to member variables. """

        self.supported_formats = ["10X", "alevin"]

        self.dir_in = Path(dir_in)
        self.all_directories = {item for item in  os.listdir(dir_in)
                                if os.path.isdir(dir_in / Path(item))}

        self.convention, self.exceptions = \
            self.detect_convention(dir_in, self.all_directories)

        print(f"Count matrix files automatically detected using the '{self.convention}' "
              f"convention.")

        if len(self.exceptions.keys()) > 0:
            warn(f"Excluding {self.exceptions.keys()} from list of samples as no count matrix "
                 f"files were found in supporting formats: {self.supported_formats}. If these are "
                 f"samples ensure adherence to supported naming conventions.")

        self.counts_directories = self.all_directories - set(self.exceptions.keys())

        if len(self.counts_directories) < 1:
            exit(f"No Count files found in '{dir_in}', therefore no samples are provided. "
                 f"Pipeline will fail.")

        self.sample_names = self.get_sample_names()

    def __repr__(self) -> str:
        """represents object in human readable form when printed."""
        return f"Contains sample names and properties of count files in {self.dir_in}."

    @staticmethod
    def detect_convention(dir_in: Path, all_directories: Set[str]) -> str and Dict[str, str]:
        """loops through all directories in the input directory identifying valid directories
        which contain count matrix files. Returns exceptions in a dictionary of the form {
        excepted_directory: reason}. Takes the naming convention from the first valid directory
        identified.

        Currently handles the following conventions:
        alevin: ./sample_name/alevin/quants_mat.gz
        10X: ./sample_name/matrix.mtx.gz
        mtx: ./sample_name/quants_mat.mtx.gz (also expects rows and columns information).

        Positive matching only - assumes convention is unknown until proven otherwise
        """
        exceptions = {}
        convention = "unknown"

        # find convention from directory structure. Warn if multiple conventions are identified
        for directory in all_directories:
            dir_contents = set(os.listdir(dir_in / Path(directory)))
            if "matrix.mtx" in dir_contents:
                # old 10X convention identified
                if convention == "unknown":
                    convention = "10X_old"
                elif convention != "10X_old":
                    warn(f"Multiple conventions have been identified. Using {convention}.")

            elif "matrix.mtx.gz" in dir_contents:
                # new 10X convention identified
                if convention == "unknown":
                    convention = "10X_new"
                elif convention != "10X_new":
                    warn(f"Multiple conventions have been identified. Using {convention}.")

            elif "alevin" in dir_contents:
                if "quants_mat.gz" in set(os.listdir(dir_in / Path(directory) / "alevin")):
                    # alevin convention identified
                    if convention == "unknown":
                        convention = "alevin"
                    elif convention != "alevin":
                        warn(f"Multiple conventions have been identified. Using {convention}.")
                else:
                    exceptions.update({directory: f"Alevin convention detected but no "
                                                  f"quants_mat.gz files found."})

            elif "quants_mat.mtx.gz" in dir_contents:
                # mtx convention identified
                if convention == "unknown":
                    convention = "mtx"
                elif convention != "mtx":
                    warn(f"Multiple conventions have been identified. Using {convention}.")

            else:
                exceptions.update({directory: "Unknown convention"})


        return convention, exceptions

    def get_sample_names(self) -> List[str]:
        """returns a list of automatically detected sample names"""
        return [str(sample_name) for sample_name in self.counts_directories]
